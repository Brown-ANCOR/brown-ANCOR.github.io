# this file houses all past and upcoming speakers and the details of their talk and affiliation
#
# TO ADD A SPEAKER: COPY THIS BLOB AND FILL IN THE DETAILS
################################
# - speaker:
#   speakerlink:
#   title:
#   affiliation:
#   abstract:
#   date: yyyy-mm-dd
#   time: 11am
#   location:
#   recording:
################################

# COMMENTED OUT SPEAKERS ARE FUTURE UPCOMING TALKS
#

- speaker: Jacob Prince
  speakerlink: https://jacob-prince.github.io/
  title: Modeling the emergence and function of high-level representations in visual cortex
  affiliation: Harvard University (PhD Student)
  abstract: "How does the visual system develop category-selective regions for faces, bodies, scenes, and words? And how can we tell whether our deep neural network (DNN) models actually capture the feature tuning that arises in these brain areas? In this talk, I will first show that contrastive learning over large-scale natural image sets naturally gives rise to category-selective units for faces, scenes, bodies, and words, even in the absence of any category-specific learning rules or inductive biases. These emergent selective units have dissociable functional roles in object recognition when lesioned, and can predict responses in corresponding selective areas of human ventral visual cortex. These findings support a unifying account of category representation that bridges longstanding debates between modular and distributed theories of high-level vision. Building on this framework, I will then introduce 'parametric neural control' as a novel, more stringent test of DNN-brain alignment. Many DNN encoding models may show near-equal performance in predicting visual responses, while relying on fundamentally different features and computations. We demonstrate this using an interpretability technique called feature accentuation (Hamblin, Fel, et al., 2024), which enables us to synthesize stimulus sets that systematically vary along model-specific encoding axes, and, to then test each model's ability to precisely modulate neural responses in macaque inferotemporal cortex. Strikingly, we find that DNNs with equivalent encoding scores on natural images can show marked differences in their capacity to control neural responses using these targeted image manipulations. This approach therefore provides a new means to arbitrate between models, requiring a stronger commitment to feature tuning properties in local parts of the natural image manifold. Overall, these studies provide an updated deep learning paradigm for understanding the emergence and function of high-level visual representations in greater detail."
  date: 2025-04-28
  time: 11am
  location: CIT 477, Lubrano 
  recording:


- speaker: Francesca Mignacco
  speakerlink: https://biophysics.princeton.edu/people/francesca-mignacco
  title: "[CANCELLED] Statistical physics of artificial and biological neural networks"
  affiliation: Princeton Center for the Physics of Biological Function (Postdoc)
  abstract: "Recent experimental breakthroughs have paved the way for collecting “big” neural datasets through the simultaneous recording of the activity in thousands of neurons. However, our understanding of the fundamental principles governing neural activity at the population level remains sparse and requires the establishment of appropriate theoretical frameworks. In particular, understanding how neural systems process information through high-dimensional representations presents a fundamental open challenge. A parallel issue emerges in the context of artificial neural networks, that operate efficiently via the interaction of billions of artificial neurons. A commonly adopted approach involves the analysis of statistical and geometrical attributes of neural representations as population-level mechanistic descriptors of task implementation. One of these population-geometry metrics is the invariant-object classification capacity. However, this metric has been so far limited to linearly separable settings. In the first part of the talk, I will present a theoretical framework that overcomes this limitation leveraging contextual gating of the input. (Reference: F. Mignacco, C.-N. Chou, and S. Chung. Nonlinear classification of neural manifolds with contextual information. Physical Review E 111.3 (2025): 035302).  Training machine learning models relies on various optimization strategies to enhance performance. These include optimization algorithms with adaptive hyper-parameters, time-dependent selection of training examples, and model refinement through dynamic architectures. While these strategies aim to accelerate training and steer models toward solutions with good generalization properties, they often rely on trial-and-error heuristics and lack a solid theoretical foundation. Furthermore, machine learning problems are inherently high-dimensional—in terms of dataset size, input dimensions, and model parameters—challenging meta-optimization techniques that can suffer from the curse of dimensionality. Recent advances in the statistical physics of neural networks have provided powerful tools to capture high-dimensional training dynamics through low-dimensional effective equations that track the evolution of key order parameters. In the second part of the talk, I will present how to integrate dimensionality-reduction techniques from statistical physics with control-theoretic methods to identify optimal training strategies, focusing on continual learning.  (Reference: F. Mori, S. Sarao Mannelli, F. Mignacco. Optimal protocols for continual learning via statistical physics and control theory. arXiv preprint arXiv:2409.18061 (2024). Accepted at ICLR 2025)."
  date: 2025-04-14
  time: 11am
  location: Carney Innovation Zone, 164 Angell st, 4th floor 
  recording:


- speaker: Samuel Lippl
  speakerlink: https://scholar.google.com/citations?user=56QHqZsAAAAJ&hl=en
  title: Emergent mechanisms of compositional generalization
  affiliation: Columbia University Zuckerman Institute (PhD Student)
  abstract: TBD
  date: 2025-03-17
  time: 11am
  location: Metcalf 107 
  recording: https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=6e330e59-b3b7-4ce6-99c2-b2d000f6746d

- speaker: Aditya Yedetore
  speakerlink: https://adityayedetore.github.io/
  title: Classical computation in connectionist models
  affiliation: Boston University Linguistics (PhD student)
  abstract: "The success of Classical (i.e., symbolic) linguistic theories suggests that at least in the linguistic domain, the mind constructs structured symbolic representations and processes them with rules of symbol manipulation. However, modern Connectionist (i.e., neural) models may provide an alternative foundation for linguistic computation: Connectionist models often lack built-in mechanisms for Classical representation and processing, yet they perform impressively on a wide array of linguistic tasks. Connectionist models may not challenge the Classical approach if they implement Classical computers. This is no mere theoretical possibility: when trained on simple symbol manipulation tasks, small Connectionist models develop structured symbolic representations, a key aspect of Classical computation. This raises the possibility that Connectionist models trained on natural data also develop such representations. However, structured representation is not sufficient for Classical computation. The processing of the structured representations by the Connectionist models must involve abstract symbol manipulation of the sort that Classical theories posit. Else, Connectionist models may still challenge the Classical account of human linguistic capacities. We study this question by testing if Connectionist models trained on simple symbol processing tasks develop Classical processing mechanisms. We find evidence suggesting that Connectionist models that succeed on such tasks do implement Classical models. To the extent that such findings generalize to models trained on naturalistic data, such a result would suggest that modern Connectionist models do not challenge Classical theories of human language."
  date: 2025-02-24
  time: 11am
  location: CIT 477, Lubrano
  recording: https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=c62c3fa9-f0ee-4704-aa1e-b28e01087705

- speaker: Ekdeep Lubana
  speakerlink: https://ekdeepslubana.github.io/
  title: Dynamics of concept learning and emergent abilities in neural networks
  affiliation: Harvard Kempner Institute (Postdoc)
  abstract: "Neural networks' scaling has been argued to yield sudden learning of capabilities (a.k.a. emergent abilities). In this talk, I will first summarize our recent work on formal models that help explain the mechanisms underlying such sudden learning via data scaling, implicating the compositional nature of a task and formation of structured representations that are shared across several tasks involved in the broader data composition. Then, focusing on in-context learning (ICL)---one such suddenly learned capability---I will demonstrate the precise configurations used for training can lead to learning of fundamentally different algorithms for performing an ICL task. This indicates the phenomenology of ICL established in past work may not be universal. Further, I will discuss how merely scaling the context size can lead to a crossover between different ICL algorithms used by the model. This can be explained via a competition of algorithms lens, which also yields a new theory on the transient nature of ICL."
  date: 2025-02-10
  time: 11am
  location: CIT 477, Lubrano
  recording: https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=e75c1379-47ad-44d1-913b-b2d000f74df0

- speaker: Ciana Deveau
  speakerlink: https://scholar.google.com/citations?user=dhVfNmAAAAAJ&hl=en
  title: Recurrent cortical networks encode natural sensory statistics via sequence ﬁltering
  affiliation: Brown Neuroscience/NIH (PhD student)
  abstract: "Recurrent neural networks can generate dynamics, but in sensory cortex it has been unclear if any dynamic processing is supported by the dense recurrent excitatory-excitatory network. Here we show a new role for recurrent connections in mouse visual cortex: they support powerful dynamical computations, but by filtering sequences of input instead of generating sequences. Using two-photon optogenetics, we measure neural responses to natural images and play them back, finding inputs are amplified when played back during the correct movie dynamic context— when the preceding sequence corresponds to natural vision. This sequence selectivity depends on a network mechanism: earlier input patterns produce responses in other local neurons, which interact with later input patterns. We confirm this mechanism by designing sequences of inputs that are amplified or suppressed by the network. These data suggest recurrent cortical connections perform predictive processing, encoding the statistics of the natural world in input-output transformations."
  date: 2025-01-27
  time: 11am
  location: CIT 477, Lubrano
  recording: 

- speaker: Eghbal Hosseini
  speakerlink: https://eghbalhosseini.github.io/
  title: Large language models implicitly learn to straighten neural sentence trajectories to construct a predictive representation of natural language
  affiliation: MIT Brain+Cognitive Sciences (Postdoc)
  abstract: "Predicting upcoming events is critical to our ability to effectively interact with ourenvironment and conspecifics. In natural language processing, transformer models, which are trained on next-word prediction, appear to construct a general-purposerepresentation of language that can support diverse downstream tasks. However, westill lack an understanding of how a predictive objective shapes such representations. Inspired by recent work in vision neuroscience Hénaff et al.(2019), here we test ahypothesis about predictive representations of autoregressive transformer models. In particular, we test whether the neural trajectory of a sequence of words in asentence becomes progressively more straight as it passes through the layers of thenetwork. The key insight behind this hypothesis is that straighter trajectories shouldfacilitate prediction via linear extrapolation. We quantify straightness using a 1-dimensional curvature metric, and present four findings in support of the trajectorystraightening hypothesis: i) In trained models, the curvature progressively decreasesfrom the first to the middle layers of the network. ii) Models that perform better onthe next-word prediction objective, including larger models and models trained onlarger datasets, exhibit greater decreases in curvature, suggesting that this improvedability to straighten sentence neural trajectories may be the underlying driver ofbetter language modeling performance. iii) Given the same linguistic context, thesequences that are generated by the model have lower curvature than the groundtruth (the actual continuations observed in a language corpus), suggesting thatthe model favors straighter trajectories for making predictions. iv) A consistentrelationship holds between the average curvature and the average surprisal ofsentences in the middle layers of models, such that sentences with straighter neuraltrajectories also have lower surprisal. Importantly, untrained models don’t exhibitthese behaviors. In tandem, these results support the trajectory straighteninghypothesis and provide a possible mechanism for how the geometry of the internalrepresentations of autoregressive models supports next word prediction."
  date: 2024-12-02
  time: 11am
  location: Carney Institute Innovation Zone (4th floor)
  recording: https://brown.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=20816c3b-87c8-454c-8207-b23c01120927
